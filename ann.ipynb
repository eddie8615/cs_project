{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import data_reader as dr\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2406 entries, 0 to 2405\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Date                 2406 non-null   object \n",
      " 1   Daily_trading_range  2406 non-null   float64\n",
      " 2   Log_Volume_change    2406 non-null   float64\n",
      " 3   Daily_return         2406 non-null   float64\n",
      " 4   Daily_log_return     2406 non-null   float64\n",
      " 5   Index                2406 non-null   float64\n",
      " 6   oil                  2406 non-null   float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 131.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2384 entries, 0 to 2383\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Target  2384 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 37.2 KB\n"
     ]
    }
   ],
   "source": [
    "data, target = dr.read_data(window=22)\n",
    "data.info()\n",
    "target.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2406 entries, 0 to 2405\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Daily_trading_range  2406 non-null   float64\n",
      " 1   Log_Volume_change    2406 non-null   float64\n",
      " 2   Daily_log_return     2406 non-null   float64\n",
      " 3   Index                2406 non-null   float64\n",
      " 4   oil                  2406 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 94.1 KB\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(['Daily_return','Date'], axis=1)\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "x_values = data.iloc[:len(data)-22]\n",
    "y_values = target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2384 entries, 0 to 2383\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Daily_trading_range  2384 non-null   float64\n",
      " 1   Log_Volume_change    2384 non-null   float64\n",
      " 2   Daily_log_return     2384 non-null   float64\n",
      " 3   Index                2384 non-null   float64\n",
      " 4   oil                  2384 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 93.2 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2384 entries, 0 to 2383\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Target  2384 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 37.2 KB\n"
     ]
    }
   ],
   "source": [
    "x_values.info()\n",
    "y_values.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_x = scaler.fit_transform(x_values)\n",
    "scaled_y = scaler.fit_transform(y_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "split = int(len(x_values)*0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(1907, 5)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 22\n",
    "trainX = np.array(scaled_x[:split])\n",
    "testX = np.array(scaled_x[split:])\n",
    "trainY = np.array(scaled_y[:split])\n",
    "testY = np.array(scaled_y[split:])\n",
    "\n",
    "trainX.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "Xtrain = []\n",
    "ytrain = []\n",
    "Xtest = []\n",
    "ytest = []\n",
    "\n",
    "for i in range(window, len(trainX)):\n",
    "    Xtrain.append(trainX[i-window:i, :trainX.shape[1]])\n",
    "    ytrain.append(trainY[i])\n",
    "for i in range(window, len(testX)):\n",
    "    Xtest.append(testX[i-window:i, :testX.shape[1]])\n",
    "    ytest.append(testY[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "Xtrain, ytrain = (np.array(Xtrain), np.array(ytrain))\n",
    "Xtrain = np.reshape(Xtrain, (Xtrain.shape[0], Xtrain.shape[1], Xtrain.shape[2]))\n",
    "\n",
    "Xtest, ytest = (np.array(Xtest), np.array(ytest))\n",
    "Xtest = np.reshape(Xtest, (Xtest.shape[0], Xtest.shape[1], Xtest.shape[2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1885, 22, 5)\n",
      "(1885, 1)\n",
      "-----\n",
      "(455, 22, 5)\n",
      "(455, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(\"-----\")\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def create_model(neurons1=10, neurons2=10, neurons3=10, lr=0.001, activation='tanh'):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(Xtrain.shape[1],Xtrain.shape[2])))\n",
    "    model.add(Dense(neurons1,activation=activation))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(neurons2,activation=activation))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(neurons3,activation=activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    adam = Adam(learning_rate=lr)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "    return model\n",
    "    # model.fit(Xtrain, ytrain, epochs=150, batch_size=16, validation_split=0.1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "regressor = KerasRegressor(build_fn=create_model, epochs=50, batch_size=16, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1500 candidates, totalling 4500 fits\n",
      "[CV 1/3; 1/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=64\n",
      "[CV 1/3; 1/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=64; total time=   1.9s\n",
      "[CV 2/3; 1/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=64\n",
      "[CV 2/3; 1/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=64; total time=   2.5s\n",
      "[CV 3/3; 1/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=64\n",
      "[CV 3/3; 1/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=64; total time=   3.1s\n",
      "[CV 1/3; 2/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=32\n",
      "[CV 1/3; 2/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=32; total time=   1.9s\n",
      "[CV 2/3; 2/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=32\n",
      "[CV 2/3; 2/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=32; total time=   2.3s\n",
      "[CV 3/3; 2/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=32\n",
      "[CV 3/3; 2/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=32; total time=   3.0s\n",
      "[CV 1/3; 3/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=16\n",
      "[CV 1/3; 3/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=16; total time=   1.5s\n",
      "[CV 2/3; 3/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=16\n",
      "[CV 2/3; 3/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=16; total time=   2.3s\n",
      "[CV 3/3; 3/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=16\n",
      "[CV 3/3; 3/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=16; total time=   3.1s\n",
      "[CV 1/3; 4/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=10\n",
      "[CV 1/3; 4/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=10; total time=   1.9s\n",
      "[CV 2/3; 4/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=10\n",
      "[CV 2/3; 4/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=10; total time=   2.2s\n",
      "[CV 3/3; 4/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=10\n",
      "[CV 3/3; 4/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=10; total time=   3.0s\n",
      "[CV 1/3; 5/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=5\n",
      "[CV 1/3; 5/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=5; total time=   1.4s\n",
      "[CV 2/3; 5/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=5\n",
      "[CV 2/3; 5/1500] END activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=5; total time=   2.2s\n",
      "[CV 3/3; 5/1500] START activation=tanh, batch_size=32, lr=0.001, neurons1=64, neurons2=64, neurons3=5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-23-1ac1646888fc>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m               )\n\u001B[1;32m      8\u001B[0m \u001B[0mgrid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mregressor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_grid\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtscv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0mgrid_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgrid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mXtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mytrain\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    839\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    840\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 841\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    842\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    843\u001B[0m             \u001B[0;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1286\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1287\u001B[0m         \u001B[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1288\u001B[0;31m         \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1289\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1290\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    793\u001B[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001B[1;32m    794\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 795\u001B[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001B[0m\u001B[1;32m    796\u001B[0m                                                        \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    797\u001B[0m                                                        \u001B[0mtrain\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtest\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1042\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1043\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1044\u001B[0;31m             \u001B[0;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1045\u001B[0m                 \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1046\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    857\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    858\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 859\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    860\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    861\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    775\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    776\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 777\u001B[0;31m             \u001B[0mjob\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    778\u001B[0m             \u001B[0;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    779\u001B[0m             \u001B[0;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    207\u001B[0m         \u001B[0;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 208\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    209\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    570\u001B[0m         \u001B[0;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    571\u001B[0m         \u001B[0;31m# arguments in memory\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 572\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    573\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    574\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    260\u001B[0m         \u001B[0;31m# change the default number of processes to -1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 262\u001B[0;31m             return [func(*args, **kwargs)\n\u001B[0m\u001B[1;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[1;32m    264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    260\u001B[0m         \u001B[0;31m# change the default number of processes to -1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 262\u001B[0;31m             return [func(*args, **kwargs)\n\u001B[0m\u001B[1;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[1;32m    264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    220\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 222\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001B[0m in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    618\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    619\u001B[0m         \u001B[0mfit_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 620\u001B[0;31m         \u001B[0mtest_scores\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscorer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merror_score\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    621\u001B[0m         \u001B[0mscore_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart_time\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mfit_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    622\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mreturn_train_score\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001B[0m in \u001B[0;36m_score\u001B[0;34m(estimator, X_test, y_test, scorer, error_score)\u001B[0m\n\u001B[1;32m    672\u001B[0m             \u001B[0mscores\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mscorer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    673\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 674\u001B[0;31m             \u001B[0mscores\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mscorer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    675\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    676\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0merror_score\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'raise'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001B[0m in \u001B[0;36m_passthrough_scorer\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m    395\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_passthrough_scorer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    396\u001B[0m     \u001B[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 397\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mestimator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscore\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    398\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    399\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001B[0m in \u001B[0;36mscore\u001B[0;34m(self, x, y, **kwargs)\u001B[0m\n\u001B[1;32m    350\u001B[0m     \"\"\"\n\u001B[1;32m    351\u001B[0m     \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilter_sk_params\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSequential\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 352\u001B[0;31m     \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    353\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    354\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001B[0m\n\u001B[1;32m   1387\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'test'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep_num\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_r\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1388\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_test_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1389\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1390\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1391\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    826\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    827\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtm\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 828\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    829\u001B[0m       \u001B[0mcompiler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"xla\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_experimental_compile\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"nonXla\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    830\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    860\u001B[0m       \u001B[0;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    861\u001B[0m       \u001B[0;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 862\u001B[0;31m       \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    863\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_created_variables\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    864\u001B[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2940\u001B[0m       (graph_function,\n\u001B[1;32m   2941\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2942\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   2943\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   2944\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1916\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1917\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1918\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1919\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1920\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    553\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    554\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 555\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    556\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    557\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/cxk858/env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     57\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "params = dict(neurons1=[64,32,16,10,5],\n",
    "              neurons2=[64,32,16,10,5],\n",
    "              neurons3=[64,32,16,10,5],\n",
    "              batch_size=[32,16],\n",
    "              lr=[0.001,0.005,0.0005],\n",
    "              activation=['tanh','relu'],\n",
    "              epochs=[50,100]\n",
    "              )\n",
    "grid = GridSearchCV(estimator=regressor, param_grid=params, verbose=10, cv=tscv)\n",
    "grid_result = grid.fit(Xtrain, ytrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score s: -0.0013819751446135342 using {'dropout1': 0.3, 'dropout2': 0.1, 'dropout3': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print('Best score s: {} using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "bestParams = grid_result.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "114/114 [==============================] - 1s 2ms/step - loss: 0.4753\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0455\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0197\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0117\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0088\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0070\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0051\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0047\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0042\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0042\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0038\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.0035\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0034\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 21/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0038\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 22/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 23/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.0039\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 24/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0037\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 25/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0029\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 26/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0032\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 27/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0034\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 28/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0032\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 29/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0038\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 30/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0032\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 31/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 32/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0035\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 33/50\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 0.0035\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 34/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 35/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0032\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 36/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0030\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 37/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0036\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 38/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0034\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 39/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0031\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 40/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0031\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 41/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 42/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0031\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 43/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0028\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 44/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0027\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 45/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0039\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 46/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0030\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 47/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0029\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 48/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0029\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 49/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0029\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 50/50\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.0029\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "model = create_model(dropout1=0.3,dropout2=0.1,dropout3=0.5)\n",
    "model_fit = model.fit(Xtrain, ytrain, batch_size=16, epochs=50)\n",
    "forecast = model.predict(Xtest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "rev_forecast = scaler.inverse_transform(forecast)\n",
    "rev_ytest = scaler.inverse_transform(ytest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA+QUlEQVR4nO2deXwV5dXHv8/NQhYISwgIhFUQBEGWoFjQugsWsX1dilr3Sq21LlUr1g319a3VulTFKlq3VsVdqRuiYN0qEpR9DZskYEhCSAgh273n/eOZy71AIHeZm+XmfD+ffGbmmWdmzkyS3z33zPOcY0QERVEUpeXjaWoDFEVRFHdQQVcURYkTVNAVRVHiBBV0RVGUOEEFXVEUJU5IbKoLd+7cWfr06dNUl1cURWmRLFy4sFhEsurb12SC3qdPH3Jzc5vq8oqiKC0SY8ymA+3TkIuiKEqcoIKuKIoSJ6igK4qixAlNFkNXFKX1UVtbS35+PlVVVU1tSrMnJSWF7OxskpKSQj5GBV1RlEYjPz+fdu3a0adPH4wxTW1Os0VEKCkpIT8/n759+4Z8XEghF2PMeGPMamNMnjFmaj37HzbGLHJ+1hhjdoRuuqIorYWqqioyMzNVzBvAGENmZmbY32Qa9NCNMQnAdOAUIB9YYIyZJSIr/H1E5Pqg/r8HRoRlhaIorQYV89CI5DmF4qEfBeSJyHoRqQFmAmcepP95wCthW6IorQlvKZQ+YZeK4hKhCHoPYHPQdr7Tth/GmN5AX2DuAfZPMcbkGmNyi4qKwrVVUeKHzeOh8HdQeHVTW9LqePTRRzn88MO54IILmtoU3nnnHVasWNFwxxBxe9jiZOANEfHWt1NEZohIjojkZGXVO3NVUeKf2nyo+taul78M3pKmtaeV8cQTTzBnzhxeeumlBvvW1dXF1JamEPQCoGfQdrbTVh+T0XCLogSo+h62nA9Sa7e9O613DpD1Z7usXtU0trVCrrzyStavX8+ECRN48MEH+fnPf86wYcMYM2YMS5YsAWDatGlceOGFjB07lgsvvJCioiLOOussRo8ezejRo/nqq68AqKio4NJLL2Xo0KEMGzaMN998E4Df/va35OTkMGTIEO6888491546dSqDBw9m2LBh3HjjjXz99dfMmjWLm266ieHDh7Nu3bqo7y+UYYsLgAHGmL5YIZ8MnL9vJ2PMIKAj8N+orVKUeOHH30DVAuh4LaQeDdsfgJrlkDQA2p0DRbdAzSpIG9vUljY+110Hixa5e87hw+GRRw64+8knn+Sjjz5i3rx53HXXXYwYMYJ33nmHuXPnctFFF7HIsWfFihV8+eWXpKamcv7553P99dczbtw4fvjhB0477TRWrlzJPffcQ/v27Vm6dCkApaX2fci9995Lp06d8Hq9nHTSSSxZsoQePXrw9ttvs2rVKowx7Nixgw4dOjBp0iQmTpzI2Wef7crtNyjoIlJnjLkamA0kAM+KyHJjzN1ArojMcrpOBmaKFilVlACeDnZZux6S+0PpI9DubOj+GuADkwI1K5vQwNbLl19+ucerPvHEEykpKaG8vByASZMmkZqaCsAnn3yyV1ikvLyciooKPvnkE2bOnLmnvWPHjgC89tprzJgxg7q6OrZu3cqKFSsYPHgwKSkpXH755UycOJGJEyfG5J5CmlgkIh8AH+zTdsc+29PcM0tR4oSETnZZ9iLsmgu+Cug8DYwBEiD5MKha0pQWNh0H8aSbmvT09D3rPp+Pb775hpSUlAaP27BhA3/9619ZsGABHTt25JJLLqGqqorExES+/fZbPv30U9544w0ef/xx5s6td+xIVGguF0WJJb4yu9z1EZQ9Ax2ugDZDAvvTx0PlXKjb2jT2tWKOPfbYPS9GP/vsMzp37kxGRsZ+/U499VQee+yxPdv+sMwpp5zC9OnT97SXlpZSXl5Oeno67du3p7CwkA8//BCw8faysjJOP/10Hn74YRYvXgxAu3bt2Llzp2v3pIKuKLHEW2yXbc+AjtdA1l/33t/hcsAL5a83ummtnWnTprFw4UKGDRvG1KlTeeGFF+rt9+ijj5Kbm8uwYcMYPHgwTz75JAC33XYbpaWlHHHEERx55JHMmzePI488khEjRjBo0CDOP/98xo6170Z27tzJxIkTGTZsGOPGjeOhhx4CYPLkyTzwwAOMGDHClZeipqlC3jk5OaIFLpS4J68PpB0H3V88SJ9sSDseuv+rsaxqMlauXMnhhx/e1Ga0GOp7XsaYhSKSU19/9dAVJZZ4iyGh88H7pIyCqoWNY48S16igK0qs8O0G2QWJDUyiSxkFNavBW944dilxiwq6osQKf/w8IfPg/VKOBgSq5sfcJCW+UUFXlFjhq7RL0/bg/VKPATxQ+UXMTVLiGxV0RYkVstsuPakH75eQAW2Gw24VdCU6VNAVJVb4Bd00PCGFtGNh9zcgNbG1SYlrVNAVJVb4nGozpgEPHSD1WJAqyOsO3u2xtasVs2PHDp544omYX8ftLIqhooKuKLEi1JALQNo4u/SWwO4FsbOplROuoIsIPp8v7OuooCtKvCF+Dz2EkEtiV+h4nV33FsbMpNbO1KlTWbduHcOHD+f666/npJNOYuTIkQwdOpR3330XgI0bNzJw4EAuuugijjjiCDZv3sw999zDwIEDGTduHOeddx5//aud8btu3TrGjx/PqFGjOPbYY1m1alVM0uKGSkjJuRRFiQBfGB46QNb/2myMrSWvS+F1ULXI3XOmDIeujxxw93333ceyZctYtGgRdXV1VFZWkpGRQXFxMWPGjGHSpEkArF27lhdeeIExY8awYMEC3nzzTRYvXkxtbS0jR45k1KhRAEyZMoUnn3ySAQMGMH/+fK666irmzp3relrcUFFBV5RYseelaIiC7kkHTzuo+zF2Nil7EBH+9Kc/8fnnn+PxeCgoKKCw0H476t27N2PGjAHgq6++4swzzyQlJYWUlBTOOOMMwCbc+vrrrznnnHP2nLO6urrxbyQIFXRFiRXhhFz8JBzSejz0g3jSjcFLL71EUVERCxcuJCkpiT59+lBVZX9nwelzD4TP56NDhw57si82BzSGriixItyQC0BiN/XQY0hwutqysjK6dOlCUlIS8+bNY9OmTfUeM3bsWP79739TVVVFRUUF7733HgAZGRn07duX11+3mTJFJGZpcUNFBV1RYkUkHnriIeBtJR56E5CZmcnYsWM54ogjWLRoEbm5uQwdOpQXX3yRQYMG1XvM6NGjmTRpEsOGDWPChAkMHTqU9u3bA9bL/8c//sGRRx7JkCFD9rxYdTstbqhoyEVRYoXsBhLBhPFvltDZDl1UYsbLL7/cYJ9ly5bttX3jjTcybdo0KisrOe644/a8FO3bty8fffTRfsePHTu2SYYtqqArSqzwVYUXbgHrzUvTvlhT9mfKlCmsWLGCqqoqLr74YkaOHNnUJtWLCrqixArZHV64BcDTBnwq6M2NULz65oDG0BUlVvh2hz5k0Y9pA9SChD87saXQVFXSWhqRPCcVdEWJFRJJyKWNc2x8eukpKSmUlJSoqDeAiFBSUkJKSnjf8DTkoiixIpKQy16CHuaHQQsgOzub/Px8ioqKmtqUZk9KSgrZ2dlhHROSoBtjxgN/AxKAZ0Tkvnr6nAtMAwRYLCLnh2WJosQbUhVByMX5AIhTDz0pKYm+ffs2tRlxS4OCboxJAKYDpwD5wAJjzCwRWRHUZwBwCzBWREqNMV1iZbCitBh8uzXkojQqocTQjwLyRGS9iNQAM4Ez9+lzBTBdREoBRGSbu2YqSgsk6pCLooRHKILeA9gctJ3vtAVzGHCYMeYrY8w3TohmP4wxU4wxucaYXI2hKXGPrxI8aeEdo4KuRIFbo1wSgQHA8cB5wNPGmA77dhKRGSKSIyI5WVlZLl1aUZopvlLwdArvGL+g+6sdKUoYhCLoBUDPoO1spy2YfGCWiNSKyAZgDVbgFaV1ImJLySWEKege9dCVyAlF0BcAA4wxfY0xycBkYNY+fd7BeucYYzpjQzDr3TNTUVoYstuKckLH8I7TkIsSBQ0KuojUAVcDs4GVwGsistwYc7cxZpLTbTZQYoxZAcwDbhIRzTCktF78hZ7D9dDjfNiiEltCGocuIh8AH+zTdkfQugB/cH4URfELeqQxdBV0JQJ06r+ixAJfqV2G7aGroCuRo4KuKLEg4pCLCroSOSroihIL9gi6vhRVGg8VdEWJBdF66DoOXYkAFXRFiQW+HUACmIarx++FR0e5KJGjgq4oscBXCZ62YEx4x2nIRYkCFXRFiQW+XeHncQHsSGKjgq5EhAq6osQCqQQTgaAbY710FXQlAlTQFSUWRJJp0Y8KuhIhKuiKEgsi9dBBBV2JGBV0RYkFUXnoKbbakaKEiQq6osSCaDx0T5rN1qgoYaKCriixICoPPVUFXYkIFXRFiQW+XdF56L5Kd+1RWgUq6IoSC0Q9dKXxUUFXlFjgqwRPmNP+/aiHrkSICrqiuI1IlMMW1UNXIkMFXVHcRpxMiZGGXDyp6qErEaGCrihuI44YR+yh67BFJTJU0BXFbfzetXroSiOjgq4obuPbZZcRj3JxPHQR92xSWgUq6IriNtGGXDypgGg+FyVsVNAVxW385eP8xSrCxf9BoHF0JUxU0BXFdWrtIlJB96TapcbRlTAJSdCNMeONMauNMXnGmKn17L/EGFNkjFnk/PzafVMVpYUgNXZpkiI7Xj10JUISG+pgjEkApgOnAPnAAmPMLBFZsU/XV0Xk6hjYqCgtC/F76MmRHW/UQ1ciIxQP/SggT0TWi0gNMBM4M7ZmKUoLJloP3R9yUQ9dCZNQBL0HsDloO99p25ezjDFLjDFvGGN61nciY8wUY0yuMSa3qKgoAnMVpQUQtYfuhFzUQ1fCxK2Xov8G+ojIMGAO8EJ9nURkhojkiEhOVlaWS5dWlGaGax66CroSHqEIegEQ7HFnO217EJESkT2DZp8BRrljnqK0QPyCToQeuqetXfoqXDFHaT2EIugLgAHGmL7GmGRgMjAruIMxplvQ5iRgpXsmKkpLwx9yidRDb2+XvjJ3zFFaDQ2OchGROmPM1cBsIAF4VkSWG2PuBnJFZBZwjTFmElAHbAcuiaHNitK82RNyidRDdwTdq4KuhEeDgg4gIh8AH+zTdkfQ+i3ALe6apigtlGhfinraAh710JWw0ZmiiuI2UU8sMuDJUA9dCRsVdEVxm2g9dLBhF/XQlTBRQVcUt9kzyiUh8nMkqKAr4aOCrihuIzXWOzcm8nN42mvIRQkbFXRFcRupBSKMn/vRkIsSASroiuI2fg89GjTkokSACrqiuE5t5CNc/Hjag6/cHXOUVoMKuqK4jVseurdM64oqYaGCrihuI7XRC7pJw0689rphkdJKUEFXFLeRmuhDLv7j9wyBVJSGUUFXFLdxxUN3jldBV8JABV1R3EZqiHrY4h5Br43aHKX1oIKuKG7jxktRDbkoEaCCriiu48KwRdRDV8JHBV1R3MYVD91/vHroSuiooCuK24gLHrqGXJQIUEFXFLdx00PXkIsSBiroiuI2OmxRaSJU0BXFbXRikdJEqKArittILXtGqUSKhlyUCFBBVxTXccND15CLEj4q6IriNr5d4EmL7hwaclEiQAVdUdxEfODbafOZR4WGXJTwCUnQjTHjjTGrjTF5xpipB+l3ljFGjDE57pmoKC0IXwUg0Qu6TixSIqBBQTfGJADTgQnAYOA8Y8zgevq1A64F5rttpKK0GPxl4xIyojuPhlyUCEgMoc9RQJ6IrAcwxswEzgRW7NPvHuAvwE2uWqgoLQm/oHvaw8aN8OmnsHw55OXBhg1QWgoeD1RVQXU1ZGZCjx7QvTuMGgVnnAGHH66jXJSICEXQewCbg7bzgaODOxhjRgI9ReR9Y8wBBd0YMwWYAtCrV6/wrVWU5o7XqQO6KA9Ou9gKd2oqHHqo/cnMBK/XtrVpA8XFUFAA330Hr70GN98Mt94K066x51EPXQmDUAT9oBhjPMBDwCUN9RWRGcAMgJycHC2WqMQffg/9tQ+hc2eYMwcOO8x65Q2xciX8+c9w770wqDvkoIKuhEUoL0ULgJ5B29lOm592wBHAZ8aYjcAYYJa+GFVaJX5B/2whTJoEgwaFJuZgQy3PPgsnnABXqYeuhE8of2kLgAHGmL7GmGRgMjDLv1NEykSks4j0EZE+wDfAJBHJjYnFitKc8TqCXrQbTj01/OMTE2HmTBh1jN1e+p17tilxT4OCLiJ1wNXAbGAl8JqILDfG3G2MmRRrAxWlReFzYugVwLBhkZ2jSxeYM8+uz/kQdu92xTQl/gkphi4iHwAf7NN2xwH6Hh+9WYrSQvGVgc+AtIHevSM/T2IiSCJUlsOMGXDtte7ZqMQtOlNUUdzEWwZViTAwjNj5gfC0gd7d4IknQHQMgdIwKuiK4ia1a+BH7MvQaDHJMGwwrFljhzUqSgOooCuKW4gXKv8L82vtiJVoMUnQN9uuf/hh9OdT4h4VdEVxi+plIDvhO1wS9GRISYDRo+Gjj6I/nxL3qKAriltUL7HL5bgn6FIL48bZkEtdXfTnVOIaFXRFcYuadSDAFgMDBkR/PpNkJxbl5NihiytXRn9OJa5RQVcUt6hdB+XpcEgvm6clWkyyFfRRo+z2ggXRn1OJa1TQFcUtatdBYTJ06+bO+UwySLX19tPTYckSd86rxC0q6IriFjXrbF7Srl3dOZ9JA9ltx7MffrhNw6soB0EFXVHcwLcbvNtgfTUccog75/Skg6/Srg8eDCv2LUGgKHujgq4oblC3xS7XV7rsoe+y64MHw5YtsGOHO+dW4hIVdEVxA7+gb8NFDz0t4KEPHGiXeXnunFuJS1TQFcUN6pwSAdtwz0MPFnT/h0RhoTvnVuISFXRFcQO/h16IiyGX9EDIxX/ObdvcObcSl6igK4ob1BaALxl2Ah07unNOv4cuYnOkg3roykFRQVcUN6jbAtXt7Xrbtu6c06QBXqDWjkNPT1cPXTkoKuiK4gbebVCVbtfbtXPnnB7nfL6gsIt66MpBUEFXFDfwFkNlil13y0P3pNml/8Voly4q6MpBUUFXFDfwlsCuJJvDJSnJnXMaR9DFEfSuXTXkohwUFXRFiRYRK+gVCe5557B/yCUrC4qK3Du/EneooCtKtEglSBXsMO7Fz2H/kEunTlBa6n590R074IEHbCGNBx6A2i2w/THwlrt7HSXmJDa1AYrS4vGW2OUO3PXQg0Mu1csgsy1UV9vc6Glp0Z1b6uDHKyCxB/w9Ce6cZttXLIcznwTfevCVQubtYEx011IaDRV0RYkWv6CXeGPjoXuLYfMpcHKW3S4tjV7QazdC2fN2/aWg9p41VswBiu+0GSS7vxDdtZRGI6SQizFmvDFmtTEmzxgztZ79VxpjlhpjFhljvjTGDHbfVEVppniL7bKozmUP3YmhVy22y7QiOBQr6NHi2x1YHwF06ABffAF3DLFt7Z+yy4q39j6uehXUaRy/udKgoBtjEoDpwARgMHBePYL9sogMFZHhwP3AQ24bqijNEhHYdoNd31btroeekGGXpQ8H2jKB7dujP7d/5AzALcDjHWDYVhi5BN4Chv4Jkq6zL2S9O22/ukLYcDgU/E/011diQige+lFAnoisF5EaYCZwZnAHEQl+e5KOrayoKPFPXQFUL7XrG2rc9dATu0HH623VIj8ZuOOh73I+FNalQhtg1EbYci4k9oZpQEkJvPINILA2AwrOgR9OsMfs/tL9F7OKK4Qi6D2wdVj85Dtte2GM+Z0xZh3WQ7+mvhMZY6YYY3KNMblFOvxKiQd8ZXbZfSaUVLrroQNk3b33dgbueOjbfrBL7y0wSKD95eDpCF0fhcUrbLreV74J9N89HxI6QNtJdrtGqyc1R1wbtigi00XkUOBm4LYD9JkhIjkikpOVleXWpRWl6fA5X0497WHnTnc9dABPW+h8F3S40m675qE7cf92zv/hIU/DgGJoN8mWu3v2Wdjo9M24A/r/AL2/hs7OB0z16uhtUFwnFEEvAHoGbWc7bQdiJvDzKGxSlJaD1/HQ69pATQ1kZLh/jc53QNfpgAfa446gVzrnaNfZLo0BEyQHP/kJvPMxDAWW/iQQYvE430D8aX2VZkUogr4AGGCM6WuMSQYmA7OCOxhjBgRt/gxY656JitKM8Xvo5Y7gZWbG5jrGY78FdElxZ/p/lSPoGQfJ3f6Tn0BSKrz5pi1UPW1a0GQnFfTmSIOCLiJ1wNXAbGAl8JqILDfG3G2McQJqXG2MWW6MWQT8Abg4VgYrSrPCL+g76uwyVoIOkNARurWFtS74S1XON4v2BxH09HQ46yx4+mm7fffdgaGUKujNkpAmFonIB8AH+7TdEbR+rct2KUrLwB9yKa21y1gLepcaWLUq+nPV+AW9gfqnv/41/Otfdr1794CHriGXZonmclGUaPCVAwaKg/KtxApPB+iQAFu3QnmUeVZqK8AHtGlgVM5xxwXWq6vBJIBJUQ+9maKCrijR4Cu3LwpLnJh0rD30tl67vjrKUSbeCqg2DedpMQa2bIErroDiYvtB4kkPJAxTmhUq6IoSDb4y8GQExobH0kNP7A7JJfa/NmpBr4TaEP/9u3WD8ePt+qJFNmmYhlyaJSroihINvnI7+qSkBFJSok+adTBScsDshsM80Qu6VEJtQuj9TzrJfvv4059ANOTSXFFBV5Ro8JbZnCslJbENtwCkHm2XDyXC2hXw/fdQVxfeOWbNghUrbP52bxiVldq3h4cegvnzYUupCnozRQVdUSLFtwtqVkBClhX0WIZbAJKc6R59a6DgLRg5Eh5/PPTjKyvhzDNh+HCoKQ+MWAmViy6CE0+E7VUq6M0UFXRFiZTiaVC3BTrdBAUF0GO/FEfuYgz0+squd3Davv029OO/co6trYVkH6R2OGj3ehk61OasUUFvlqigK0o4iNeWZ/vxStj+MLS/AtLGwebNkJ0d++sn97fLn59ol0uWhH7s3LmB9TZAeufwrz90KFT4oNqF9AOK62jFIkUJFamB4v+DkrsCbZlT7fjsbdugZ88DH+sWCR3t8swToOCndjp+aSl07NjwsX4PHSAVSI8gRDRkCHwC1JaFf6wSc9RDV5SGEIGtl8Ga9lbM24wM7EvuZ8Mt0DiCbpLs9HtvKZxwgrXts88aPq62FnJz4be/hfvvhyH97XjycMnOht3Yl6qxwOuNftJUK0YFXVEawlsCZc9B8gDo/rpNI9vxOujm1NrMz7fLxgi5gM1L7tsBRx9t863cemvDOdKXLrXFpY87Dm66CRJqwKSGf+2sLCvonhgJ+t132xE1RUX2ua5bF5vrxCkq6IrSEP4EXJ1ugIyzwdMGuj4Mi/vAZZfBhg12f6MJekfroScnwznnwMqV8OSTBz9msVOXdKTz7UJ2gycCQU9IgIS2kFgH4gv/+IZ49lm7vPRSm+2xf394+233rxOnaAxdURpiTxGLoFznP/sZfODkq5s/Hzp3tuLTGHg6gs95KfncczB7thX1g7Fypf0A6NfPbvsq7YzPSGiTAVTY0niRePkHwuuFHTvs+vvvB9onT7YTqfr0ce9acYp66IrSEPsK+pYtATEHO1Hnl7+EpDAm6kRDQgfrofs54oiGMzCuXAmHHQaJiTbuHqmHDpDa3i6Da51GwxtvwMKF9oOposJmd5wyxe77/HNbOOSVV9y5Vpyjgq4oDbGvoM+ZY5d3B9X7vLYRM0h7OoJ3R2B74EDrwR6scPOqVba0HNjROvgi99D9o2PceDG6aZMNG+Xk2G89ABMnwt//bkNZxx5rQy8zZ0Z/rVaACrqiNIS3HkHPyrIvIz/91I4yGTDggIe7TkJH8G0PCPjAgbae6Q8/1N+/qgrWr4dBg+y27LbLSD30do6g17owucgfHz/tNBu2uuUW+1LU4wmEWCZPtuPt3cgDH+eooCtKQ/h22mVChhXRTz6BU06xonPiifDTnzauPW2GW5t2/9dujx9vbXn00fr7r10LPl/AQ/envo3UQ/fXIS0+WGnhEHnzTTjySPjoIygshHvv3b/P2WfbWbK33x5+7ppWhgq6ojREcMjlu++s8JxyStPZk3G2HYuefzpUr7YvY3/+c3j9dcjL27+//4XpnpBLlB56+yy7LIpS0H/80U52+p9f2G3j5Gf37oAfToDC60HqbPreO++0sfZ33onumnGOCrqiNISvHPuvkmpnZrZrZ+O8TYWnLXR/yeZiL3WSc40YYdMPDBhgvd5gVq60QjlwoN2O1kPv6NQhLd4S2fF+Pv4YkgXOeQpWGdiYA9WrYONIqPwMSh+BHU9CXbENb7Vvb1+cKgdEBV1RGsJXDqYtnHEGvPee9RY7R5AHxU3anQltz4SKd6D8DTg8qDboSy/t3XflShuPTnU88mg99E7OtbZvjex4P+vXw0mAcc5T/R1sOBxqN0D6REg7GQp/D3lZUP2Fzck+e/bBX/62clTQFaUhfOVQ6bFDFe++G/7wh6a2yJJxPtTlw5ZzYOA7gfbPPttb9BYtgmHDAtt+QY/UQ+/U3S5Lt0V2vJ/KJXB9AiT2gn5rA+0950CP16HrY4G2wivhmgK4fTOsXhbddeMYFXRFASi8DvJ6Q+VX++/zlsNOselxb7+94TqcjUW7syCxt11P+jyQUre0FN56C66+GrZtho6rYdSowHH+kEukHnqSkwOmLApB95bBZW9Dthe6/MVmkUw7ATJvhfSTwZMCbQZB/0I45CmoWQNd58OxwPJ7Ir9unKOCrigAFe9B3Q/ww3FW3IPxlkLRLhg9uklMOyAmAfotg873gOyE97ICo0QuvxymT4cnesFzwNFZgeOi9dBNG7vclh+x6XiL7XJJNrT7pV3vNRey/nfvfoldIONXthB3xnmwMQmS/xP+9Wpq4Jln7IddHBOSoBtjxhtjVhtj8owxU+vZ/wdjzApjzBJjzKfGmN7um6ooMURqoO0Z1jss/RvUbrbtvkoo+xyW1sGYMU1rY3142kKn663gZZbaCU7GQJmT3jbH8aaHdg8cE62H7kmxy7XLI0+etfQbu9w6vOFvPJ40ODQfur0I27OgfZAo19TAhAnwq1/BrgOMiy8vt7VQr7jCTlTyeiOzuQXQoKAbYxKA6cAEYDBwnjFm8D7dvgdyRGQY8AZwv9uGKkrMEAFvISQfDl2n27YdM2DzBMjrBsleyDsUfv/7prXzQHjSbaiCOkgVGOz8e55/vk0LAJBeE+jvloeezP4jakLlVmdmbWaIKYcTMsAkgrcPdKmFOmduwPTpdgz7Sy8dOD3AVVfBgw/a9eXL7dyBCRPsh0GcEYqHfhSQJyLrRaQGmAmcGdxBROaJiPOxzzdAI6WdUxQX8JVZDz2xq43ltjsXSv4Xdn0EvsOsi3L8TZAWoQA2Bond7LJuK5zkVDPq0gVwvN+6oCGG0XroxvHQs7Pgm28iO4fHyQMz4ezwjkt1PqwK5tnlW2/ZtAH9+8Orr+7fv7LSjl8Hm3HyuOPs8qOPIrcdYPNEyD+z4X6NTCiC3gPYHLSd77QdiMuBD6MxSlEalbof7TLBGV/d7QX2/GssuQRuB0Y3w3BLMIlOSKXwGpjyJnTFhojE8ULrgoYYuuWh9+8FX34Z/jDC2lqgwq637RresZ1/Ypc7zwJvtR3Bc/TR8ItfwH/+Y3O+B/PYY7ai1Cef2JE+//kPbNxoZ9Z++ml41wZbgrDsBdj1PlTMimwIZUlJzMI+rr4UNcb8CsgBHjjA/inGmFxjTG5RUZGbl1aUyNnlTFZJdMZXe1Lg0PWQ/R68OtfmbRkypOnsCwW/h77rI0jYAp8PhbMngtf5sNrLQ98JmIAwh4vfQx/Q2xaiuPLK8I4vLAT/Z4mnXXjHDp0Es7D52L/52GZnHD7cxsb9VZnKy23+muJiuO02K/Ynnhg4R4cOdtTPvpWe7r7bzratD18F/HAyrE6ErZcE2uv2mVyVmwsXXrh/wZGCAvs3NG4c9O1rM0rGgFAEvQAIDnRlO217YYw5GbgVmCRSf15NEZkhIjkikpOVlVVfl9bF0qV2oorSdNRshG3X2fXErtZzqqmxY6N35cCsWXDJJTbtbHMmMeilZ8ZF4FsKZU9DXaFtC/bQq5dB8sDIh1+aZLscOcQWovjHP6ywh8qWLeCvfheuoGdmwk+dcRmvOxWjhg+HY46x6//3f3ZG7IABNgRTV2dFfd97HT3aevd+D/uTT+yEsXPPtaK8LxWzofJTSD8dsv4KnZ1Mm8V37u2l3367FesRI+z1/fteeMGmWa6shJNPhqOOCu++Q0VEDvqDLYKxHuiLfQ2yGBiyT58RwDpgQEPn8/+MGjVKWi133inym9+IOJmppU8fkW+/bWqrWidlr4isxP6cdZpIZqb9nSQliZx0kl1ftaqprWwYn8/ew+r2Ir5qkfUjA/e1EpFVaSLlb9p+a7uLFPwquuutShYpvFlk6VL7jJ54IvRj33lH5LeOXb7a8K9d+E977EBEUlJEqqtt+4knBv6n/D99+9p73pennrL7V68Wuegiu56QINK+vUhyssiSJSIVH4tsf9IeX3iTvWdvlb3nb+cEnu2uL+w5y8qsPZ06Ba7/4osiFRUi/fuLHHts+PdaD0CuHEivD7Rjr05wOrDGEe1bnba7sd442DrghcAi52dWQ+dsNYL+/PMiv/qViNcr8sgjIs8+u/8fnV/Uvd6mtrb1sfUqkVUpIk8/bH8PnTqJGBP4vbj0T9goVG8Q8Vba9bLXRVYmimwcK7J7kciqdCs+P5xmlyWPRHet1e1EfrzOrvfqJXLuuaEf+8QTIjcisjIlsmtXzLb3MBKR446zbVXLRbZcJvLJNSK3/lZkyBD7+3voofrPMX++3Z+TY5fdu4t8/71IYaFIVpZIv34iKzs4H4YpIqs7imw4WmTjxsDfxqlBH5hlr4rMvFjkTkS+fVfkzTf3/x9/6y177erVIr66yO5dXBD0WPy0CkHfujXwyzz99P1/wQMHinz8scgdd9jtxYub2uLWRclD9p/x0y6B38mmTSLFxfZ3cd99IgUFTW1l5Hh3B7zT2kIreCsRWdNFpHp9dOdekyWy9Uq7/stfimRnh37stdeK3J1gzxEJlV/b+xiHyE1XipQ+JbK6bdC3kRSRRZ+JXHCByK5d9Z9j1y7riYPICSfsve+//xXJai+yGJFvEZl1pP1Wkz9N5Pe/3/t/2H/NNV1Fcj12ff0wkcpvRYYODfQ78UT7u6gtdD5QH4zs3uXggq4zRWOJv0xZp052vV8/6NjRth1/vM1ffcopdlYfwLx5TWJmq0QESqcDBq4PmsLeq5eN0w4bBjffDN27H/AUzR5PSiB2nNgFuv0DBhTDoT9Act/ozm3a2BJ02x+D366Es/JhTYg5VubPh56dwo+f77l2W7v807Vw5Tb48Td2DkGfxZCSYysp9VxiY9kHGmqalhZIJ3z66XvvG1oO89JsgPn+DDh/HWQug6l5dtQMwFNP2Ti9vza3dxek+2DbAPuOYtMx8MEddtz7yy/bd2XGQPUi27/N8MjuvQFU0GPJ/Pk25WdRkZ1ynJcH27bZN97z5sGpp9p+vXpZsf/886a1tzVRtQBq18GP18IS4J57IhvG1tJIyARPhKNbgjEpNmnZtmug6xK4Enjh5weeremnuhq+/x66ZdhZrpHg/yA45kgweZB8GPT+ClKGQZ8FkDIaSh8GX5UdZnggLr3ULv3/hwC+3VBwHiRstS9/b3/LjqSZPh0+dEZjn3CCrXm6bBn4fg/vwp5hmMkPwoAi+3ySvrSTvH5moPTXUHSbnbAGkDI8sntvABX0WPLtt/Zttsdjh0oZY0dL1Of1DR9u/0Aai+plNkFSa6XyM7ucUwkpKXDjjXsPbVMOTm0e7HRmiXZ/BXb3hFHrICPDVhiSA4zPXrgQhlVD73W2eEUk+D8IfOVQk2dHnpigAt1Zf7YpeNekwoahUHIfVHy0/3muucbWLfVnoqzZCOsH2fJ+PT+F/ttg2Ek29/3tt9vx4/fcEyiykZxsv2V3Hmq31wMjT4OETtDmCKheYtu3nAflL0PJvYFnltApsntvABX0WFFZaYclHn10aP2HDLEefJULhXcbwrfL/qFvmXzgPtu22eFo69fH3p7GxlcN5f+yQ/dmL7RD3lJSmtqqlkXqOLvsdDO0Oxt6nA+DEkF8Nh3AihX1HzdnDvg/N9Mi/AD1e+jbrgOptLN7g0k/CQ55BtoMtcJedAsU/MIWygj22I0J1C3d/jCs72vHlXe6wWZ+TGhv9z3zDFxwAfzmN3DDDfZDK5gcZ8Zo2xOsyIO9dvWSwMQuP0l9of2vI7vvEFBBjxULF9oxzaGONx0yxNZ9XL06tnYBVH5hl7u/rn9/ebmtk/nrX8Nll8Xensam+HaoXgppp9riD0ce2dQWtTyy34PDdkGX+2yOlaQ+4KmD9c50+jlz6j/u449hUCdIOhQOeaz+Pg2xb8goqf/+fTpcDn2XwGEV0Od7G1fPy4J1fQKpD4KpdDI49v4Kuvx173HrXbvaePyTTwaKhATT/wS7HP6bQFubYeAtgTXt9+7bLw8OmdHgLUaKCnos2L4d/ud/7PpRR4U2PdifROn772Nnl59KJ1acmG09qZKSvfc/8YStsH788SD/genDYPsLUJsPVYtsbLIlU7cFTCpUX2e/SQ0a1NQWtTwS2tssiH6SnJesVWPguH7w/PPw9NN7/z3v2GHfK/VrC4kHyx4SJm32zRUYhEmw8eqs+4FEWxBkTTqUvbx3v5o10PYXkBrBhJ+0n0K3l2x+ej/tL4DMO6Hj1ZB5G2TdBz1ng/HENJ9+M5/+1kJ59lk4tRhuAEqzoXIY9MkN/CJrnenCSUGx9MMPt8Vw33/fzkyMJdVO0eAd62HUEDjsMPtTXAxTJsIbD8MJx8MzlVADsBS2XQL+wSBdHoFO18bWxljiLYPkQbDGSf3qr7WpRE7wqJlr+8FZn9gXh3372lBiTQ1cepr91ppZB0ku5e/rsxCSQsjYmHkTdLrRjj6pmm+n77edaLM4Sp2NxbedFJkNJgHan793W0InyJoW2fmiQAXdbbw7Ye0cuB5IOwySvLZWYs1yIBFqN0L+BEgZZUXej8cDZ54J//ynDXnsG6dz1UZHmdOq4FRg7RrYsQZOBo75Bo4Bii+Cmsuw2fqcbxjeoyFhvh0d0pLxlYMnw34LAfXQ3cBfOQlgxEDI2WGH6M6ZYxN4lT0Hf/4WChMgscQ9D73NiND7GgO9v4Cdb8AWp3yf53D44Xig1r5TaeFoyMVt1o+H6z+2uSr6vAK9nPDGhqG2AG7+BLtdtRDKX4e6IqjbBrs+tTHrXbvg/hink6/bBr4Eu/434APgaeCCoD6dndh5n6CvzJfU2dinv9pMS8VXbkMGS5da0ekaZsY/ZX88bSD9NLuelA8LFsDbb9thu3+5DzKdXOX/vNCOX090yUMPN3xhkgIfJnVboGY17HbKDqaGOIChGaOC7iZ1xeD9GqqAxddDykhI6m3f5id0tSW0AFKcON2Wc2H9AMjrCptPhpEjbeWV++6zQx5jgYj10DcOgMUmkDmv3bnQvwh6vBvo22EKpAS9MMxdCIXeQMKnlorfQ//+e5tEqbnUCG3p9PzIxqGrl9kUs6nYgtorPoROTr6+2uftMvnQ6K6V/T5kfxDZsf5EZnVbbHZKsEWqDxaLbyGooLuF1MCa4+367Avglw8G9vX6FAb8CN1fhkM3QffgRPxBYiK74fHH7UzFe2JUCNdXYa+zLgVu7QcDd0OfJda2xM7QbhL0W2dHMBzylD2m58fQe4ENCS3cCJu/b9nVXnzldrbh0qVW0BX3SBllQ3JbL4Gtl8INP4NnT7L70pxvp6njIH1CdNdpezq0jfAce4qBOIKePGj/oY8tFBV0t6hZA57lkAdc/MCBvb6kXtZr73AV9Pocsv8d2Ocrt19Rp0yxL0fzoyjCeyD88fPNuyDb+dqbMtS+2PGT3G/vEQzpp0Bqji3zlXQIeErtV+qWiq8cfii1sxZV0N2l043Q0XlhvvN12JwD3T61otljJvScax0E04TS40kHT3uo/Ap2zYH08U1ni8uooLuFz6lx+Lc2cEi3g/c1Bg6ZDmnHQto4W/w2+BznnGNDI5984q6NVUthuxOf31AGPUOs5+gnPR1OOhc6AiuXuGtbY+Grst+m3v3Ejuw5s/mVEWvReNpA10egw28DbR2vsc5LQgaknxB56Ts38ZXBrvcAX+SefjNEBd0tfE4uhzYRTOn1OCNa/IJ+xBHQubN7ybpEoOR+2HRUIJfEmpLwBR0g8zC73PCdO7Y1Nr5yu9xUYr8JtY0wn4hycLrcD73+AwO90PVvkNjMCtqk/8wuM2+PfMZqM0SHLbqFX9BTM8M/1j+V2euIjcdjJ/XMm2fFONqXdtXfQ9HNdjpyxnmw7VlYnxdZWTX/eOPSECZAicCuD+zMvIxz6u+z8y07Lj79FEgeAAkdw7cpHPyCXoF9Ca3EBk9bSDuuqa04MD1eB2Tv0GIcoB66W/gFPdyitxAQdL+HDjaj2+bN7uRSqV5ul91ehbezYHCeFbShQ8M/V0qOXSavDeG630H+RDuax1dhh2iKD2o323cO3lIomAzFt8Gmo2FtZ6h4P3ybwmHdYrtUQW/deFLjTsxBBd0KzM5/w+7/RncevxhnRCLo+4RcwAo6wNy50dkFVtB9CdBuMFxxRaA9khmSiV2gsgNcWQ5rDoHie/YfxrhrHqwysPOdQFvBuZDXBVYnwLpesH4grO0E1EL2hzZjHx4oe972L/snbLk4fPv2pbZ27+13nOK8I4+zL6AVJY5QQa94DwomwaafRJejxOuIcYcIZsDt8dDLA22DBtkY97vv1n9MqIjPJtX/MRX82Uo7d4YuXaBNhHmx6xzP1lcIxXfAprF2opTUQcWHsNmJSe74e+CYXR8G1ttfBnigIhOmG6gcCS8Ww8Juziy+y2HrRVD+4v7Z6g7G7t12MovPZ7fXr4eeyfDB9bD4eRg71n7IeA38X2yqritKU9IyBX3bNpslL5jaLZDXA8qdfMMiUHgDbBgB1av3FgbxBXIxV7wXaI/GS99VBD4gMxpBD/LQjYHzz4ePPoJNmyKzqWaN9YZ3zYaNzgSil16ywyGjCeVkPgITgC9n2AkedVthYw5sPAryg6q/eEsg4ZDA9kXAT4HKP8FhZXBuOjwuNg/5DTfA05ttv/JnA8fUhjF0c8YMmxTtpJNsOOWLY+EzoN8jwKVQ+jX8EpBJoeX/UJQWRssT9PJXIbcvfDYY/u86K3YFBVCVaycKbDkbZs6AOWOg9CHrnW4YBF+nwc39bXKgzSfBuv5QsxYq3oG0U4AE2HYDFF4HtT+Ebs+OHfD738OGZVAJ9Ord0BH740kHzN6CDjYVQGoqnOYkNaoP326QoLBCXbGNQ2+bCgVnWa//hcFwTTH87nf2Q6JNGzsEMVL6DoGSdjB3np3gcegGm7Cr2nlRmtQnML26LEjQ+50L2xOd1AZpsN0ZOllZaT+An1oFV+8z5LN2Y+h2feVM4f7sM6j4Ho7eAu8BD3SE3cAridAG6Htd2LesKC2BlifomzdDaSWcAFT8zSaoz86Gb2YG+mz8DfT6FlYHjXfd5oVL18H159lqNXWbYP1hgEC72yHhYptjovRvdpZbqLz4op3d+flsqPLAhAjGtBqPHRUQHHIB6N/f1i5cvdpmY1y7z4vIys9hTZoVb7DJ+zefbF9Ebv+L/Wbi+wPctwJ2YTPfuYHHY4f8vfqqtS2xi82+mHa83d/9FWjrJPF/dhn8Efj0LHjxn3DVVdaT7t0byspg2jT7bWvdOhvTv/t1+KwXvOZca12IZfm8XivkF1wA/3oO3hwNdYkw/HX4x3bIfhtSPHZCSdpYd56DojQ3DlQ9OtY/o0aNiqzk9e23iyQkiCw7XmRRisjf/ijSs6fIPQmBCtwrEfmqjYivVuT9m0R+i8jITNt+KXv3m3OnSEqKrcy9a5fIj9eLrEq2FdP91JWL5E8WyT9XZNtttnK3n+OPt8c+31lkUbfI7knEVhUvuHD/9srKQOXwww8X2bgxsG/zr4Lupa/Iqgy7vvUqkSWfi9zyR5Fjj7XH3nWXyI4dkdu3L4WFged2zTUixcUi674T2T7DVjf/2c9EEhy7H300cNzOnSLTpon07i1y1FH2uPp4/x2R5YjcnSVSVBRor6kR+fe/RTZtCrT9+KPIT39qr/XGGyJFd9nnUPrM3uesmCtSPsutJ6AoTQKQKwfQ1ZYn6NXVIl9/LVL+bkDM1l8p8nKSyOtBQr3+ssAxL74osnixyHd9RBb0tPtfHSDSh4BYgsjNN4s8f7HdvypVpK7UHl/+zt4fAiWPiuxeLLKku8i9iNx7r8gPE0XWj4jsnkRE1g2x566Yu/++BQtEnnxSpF07keRkkQcftM/g3z32tusfh4iUPCJSsdMKpv++Lrts/3O6wV13iaSl7f0MH35Y5PHH7fq114q88or9nUXCwi4iXyNyGyIFBbbtj3+0505NFZk927bdcottGzFCpPI7kZWJIgXnu3GHitLsiC9BD6Zygcim4wOC9r+IzMu265Xf7N//x+sCffMeFbn4YpEZM0QqKkS6d7ePox0iK4zts3Gs9fYKp4qsNCLeCpFVadaLL74/cK5dW6wdG4+N/F52fWHPVfjHA/fZuFFk4sSAeM5E5It0kcUZIkc7bRdfLNK1a8BbfeIJe3+x5LnnREaPDnjsYD30mprozrvja5HcFPtcRqaLXH21yM8ROfdokeHD7YfbGWfY6w0aZL3/TSeKrOkiUncAz19RWjhRCzowHliNTT01tZ79xwHfYQfGnR3KOV0RdBEbDin+s0jB30Su+qXI5uUBz3pfyt4IEuEv9t63YoXI735nH8m4sSKbfrm397vqUJF//lNk3WCRr0aK3Mfe+1ci8sOE6O5lw1H2g+Gg91sn8t57Ii+/LLK6rw0FiVjxPP10a/+pp4p89ll0tkTC++8HBH3LFnfOWVNgn+1NHUQyg5/1UyL9+gWud+21IrsX2n3Ff3Hn2orSDDmYoBu7/8AYYxKANcApQD6wADhPRFYE9ekDZAA3ArNE5I2GYvc5OTmSm5vbUDd3qSu2hWIB+m2A5D779/nXv2wJuKNGwxGHwhULoN0a+CYTLi2B5cfaQrgitsxUvxLAGYHSbjL0eCVy+368GnZMt7UJuzwEu7+x0+Y9bSH9RPtCLzgr4ppOkHE+HPK43fb57IifSHK0uMV770FVFZx9tnvn3HgU1GyA6kMhaX6gPeUWyB0Gsz6AP42DhDuAOluIN6GDe9dXlGaEMWahiOTUty+UXC5HAXkist452UzgTGCPoIvIRmefL2prY0liZzsrsey5A49D/tWvbFrVG26Alatg9g54+XL4uzMl/ZUv4H+ANonQ+ULodAPszoWKt2zq0GjImGzHwu98C3a+WX+fDlfCIX+34+h9pZDQObDP42laMQeYONH9c3Z7DjafEhDzASWw8Wio+jOc/Ayc9Zwdb19XCN3fUDFXWi2hDFvsAWwO2s532sLGGDPFGJNrjMktKiqK5BTR03Y89Hh1b093Xy6/3I4vLywEbw+4/EvI3WaH2hWn2Eosif1sitDEbtDuDCs6bSJIdhVM2jjouxBSxzi2/hz6rYfuM8Ek27adb8O2G+GHn9rthAiSgbU02gyBQwug/a/tLNOETtBvpa1juf1Bpz7kFuj+GmSc1fD5FCVOadRx6CIyQ0RyRCQnK6uZpdOsj+RkeOwxW51HBF55BR7ZAqlPw4Cl0ZfROhBJTvWUjPNsdsOMX8KAUug6HbyFVsR2f237tAZBBztzttvT0O0fznYiZE61k8N2vglpJ9kq7orSigkl5FIABH+Pz3baWge/+IX9qamxAg/Q+9exvWaX++1My7ZBxRc8aZB6zP59Ezvv39Za6Hil/VEUBQjNQ18ADDDG9DXGJAOTgVmxNasZ4hfzxiDxEOjyZ1v9JZg2w/bvmxSjbwmKorQ4GhR0EakDrgZmAyuB10RkuTHmbmPMJABjzGhjTD5wDvCUMWZ5LI1utZgE6LcaOv4BBmy3P7EK+yiK0uJocNhirGiSYYuKoigtnIMNW2x5ybkURVGUelFBVxRFiRNU0BVFUeIEFXRFUZQ4QQVdURQlTlBBVxRFiRNU0BVFUeIEFXRFUZQ4ockmFhljioBNER7eGSh20Zx4QZ9L/ehz2R99JvXTEp5LbxGpN7thkwl6NBhjcg80U6o1o8+lfvS57I8+k/pp6c9FQy6Koihxggq6oihKnNBSBX1GUxvQTNHnUj/6XPZHn0n9tOjn0iJj6IqiKMr+tFQPXVEURdkHFXRFUZQ4ocUJujFmvDFmtTEmzxgztantaUyMMc8aY7YZY5YFtXUyxswxxqx1lh2ddmOMedR5TkuMMSObzvLYYYzpaYyZZ4xZYYxZboy51mlv7c8lxRjzrTFmsfNc7nLa+xpj5jv3/6pTVhJjTBtnO8/Z36dJbyCGGGMSjDHfG2Pec7bj5pm0KEE3xiQA04EJwGDgPGPM4Ka1qlF5Hhi/T9tU4FMRGQB86myDfUYDnJ8pwN8bycbGpg64QUQGA2OA3zl/E639uVQDJ4rIkcBwYLwxZgzwF+BhEekPlAKXO/0vB0qd9oedfvHKtdhymn7i55mISIv5AY4BZgdt3wLc0tR2NfIz6AMsC9peDXRz1rsBq531p4Dz6usXzz/Au8Ap+lz2eiZpwHfA0dhZkIlO+57/J2zN4GOc9USnn2lq22PwLLKxH/AnAu8BJp6eSYvy0IEewOag7XynrTXTVUS2Ous/Al2d9Vb3rJyvxCOA+ehz8YcWFgHbgDnAOmCH2MLvsPe973kuzv4yILNRDW4cHgH+CPic7Uzi6Jm0NEFXDoJYV6JVjkM1xrQF3gSuE5Hy4H2t9bmIiFdEhmO90qOAQU1rUdNijJkIbBORhU1tS6xoaYJeAPQM2s522lozhcaYbgDOcpvT3mqelTEmCSvmL4nIW05zq38ufkRkBzAPG07oYIxJdHYF3/ue5+Lsbw+UNK6lMWcsMMkYsxGYiQ27/I04eiYtTdAXAAOct9LJwGRgVhPb1NTMAi521i/GxpD97Rc5ozrGAGVBIYi4wRhjgH8AK0XkoaBdrf25ZBljOjjrqdj3Ciuxwn62023f5+J/XmcDc51vNnGDiNwiItki0gerHXNF5ALi6Zk0dRA/gpcapwNrsPHAW5vanka+91eArUAtNtZ3OTam9ymwFvgE6OT0NdgRQeuApUBOU9sfo2cyDhtOWQIscn5O1+fCMOB757ksA+5w2vsB3wJ5wOtAG6c9xdnOc/b3a+p7iPHzOR54L96eiU79VxRFiRNaWshFURRFOQAq6IqiKHGCCrqiKEqcoIKuKIoSJ6igK4qixAkq6IqiKHGCCrqiKEqc8P+mT1JMk+FbdAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rev_forecast, color='red', label='forecast')\n",
    "plt.plot(rev_ytest, color='gold', label='target')\n",
    "plt.legend()\n",
    "# plt.savefig(\"images/single_layer_model_pred.png\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Score: 0.004088834838339996 MSE\n",
      "test Score: 0.0639439976724946 RMSE\n",
      "test Score: 0.116710224804941 MAPE\n"
     ]
    }
   ],
   "source": [
    "testScore = mean_squared_error(rev_ytest, rev_forecast)\n",
    "print(\"test Score: {score} MSE\".format(score=testScore))\n",
    "root_testScore = mean_squared_error(rev_ytest, rev_forecast, squared=False)\n",
    "print(\"test Score: {score} RMSE\".format(score=root_testScore))\n",
    "mape = mean_absolute_percentage_error(rev_ytest, rev_forecast)\n",
    "print(\"test Score: {score} MAPE\".format(score=mape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}