{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "from arch import arch_model\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error, r2_score\n",
    "from tensorflow import keras\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    price = pd.read_csv('dataset/kospi.csv')\n",
    "    oil = pd.read_csv('dataset/oilprice.csv')\n",
    "    gold = pd.read_csv('dataset/goldprice.csv')\n",
    "    data = pd.DataFrame()\n",
    "    data['Date'] = price['Date']\n",
    "    data['Daily_trading_range'] = price['High'] - price['Low']\n",
    "    data['Log_Volume_change'] = np.log((price['Volume'] / price['Volume'].shift(1))) * 100\n",
    "    data['Daily_return'] = price['Close'].pct_change().dropna()\n",
    "    data['Daily_log_return'] = np.log(price['Close'] / price['Close'].shift(1))\n",
    "    data['Past_vol22'] = np.sqrt((data['Daily_log_return']**2)).rolling(window=22).std() * np.sqrt(252)\n",
    "    data['Index'] = price['Close']\n",
    "    data['gold'] = gold['Close']\n",
    "    data['oil'] = oil['Close']\n",
    "\n",
    "    volatility = np.sqrt((data['Daily_log_return'] ** 2).rolling(window=22).sum() / 22) * np.sqrt(252)\n",
    "    vol10 = np.sqrt((data['Daily_log_return'] ** 2).rolling(window=10).sum() / 10) * np.sqrt(252)\n",
    "    # target = yz_vol_measure(data)\n",
    "    # target10 = yz_vol_measure(data, window=10)\n",
    "    target22 = pd.DataFrame(volatility)\n",
    "    target10 = pd.DataFrame(vol10)\n",
    "\n",
    "    data['Target22'] = target22\n",
    "    data['Target10'] = target10\n",
    "    # data['Target10'] = target10\n",
    "    # data = data.dropna()\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def evaluate(predict, target, title):\n",
    "    print('--------'+title+'----------')\n",
    "    testScore = mean_squared_error(predict, target)\n",
    "    print(\"test Score: {score} MSE\".format(score=testScore))\n",
    "    root_testScore = mean_squared_error(y_pred=predict, y_true=target, squared=False)\n",
    "    print(\"test Score: {score} RMSE\".format(score=root_testScore))\n",
    "    mape = mean_absolute_percentage_error(y_pred=predict, y_true=target)\n",
    "    print(\"test Score: {score} MAPE\".format(score=mape))\n",
    "    r2_test = r2_score(y_true=target, y_pred=predict)\n",
    "    print(\"test Score: {score} R2 score\".format(score=r2_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def plot(predict, target):\n",
    "    plt.plot(predict, label='predict')\n",
    "    plt.plot(target, label='target')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split:  1856\n"
     ]
    }
   ],
   "source": [
    "print('split: ', split_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def ewma_estimation(data):\n",
    "    sqreturn = np.array(data['Daily_log_return']**2)\n",
    "    estimation = []\n",
    "    estimation.append(data['Past_vol22'].iloc[0] / np.sqrt(252))\n",
    "    weight = 0.94\n",
    "    for i in range(1,len(data)):\n",
    "        pred = weight*(estimation[-1]**2) + (1-weight)*(sqreturn[i-1])\n",
    "        estimation.append(np.sqrt(pred))\n",
    "\n",
    "    estimation = np.sqrt(252)*pd.DataFrame(estimation, columns=['EWMA'])\n",
    "\n",
    "    # plot(estimation, np.array(data['Target22']))\n",
    "    print('-----EWMA estimation done-----')\n",
    "    return estimation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def create_gjr(data):\n",
    "    data = data[22:].dropna()\n",
    "    data_cleaned = data[22:].dropna()\n",
    "    logreturns = np.array(data[['Daily_log_return']].dropna())\n",
    "    target = np.array(data_cleaned[['Target22']].dropna())\n",
    "\n",
    "    gjr_pred = []\n",
    "    for i in range(len(data)):\n",
    "        train = logreturns[:i + 22] * 100\n",
    "        gm = arch_model(train, p=1, q=1, o=1)\n",
    "        gm_fit = gm.fit(disp='off')\n",
    "        pred = gm_fit.forecast(horizon=1)\n",
    "        gjr_pred.append(np.sqrt(pred.variance.values[-1, :][0]) * 0.01 * np.sqrt(252))\n",
    "\n",
    "    print('garch pred length: ', len(gjr_pred))\n",
    "    print('target length: ', len(target))\n",
    "    # plot(gjr_pred, target)\n",
    "    gjr_pred = pd.DataFrame(gjr_pred, columns=['GJR'])\n",
    "    print('-----GJR-GARCH estimation done-----')\n",
    "    return gjr_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def create_garch(data):\n",
    "\n",
    "    data = data[22:].dropna()\n",
    "    data_cleaned = data[22:].dropna()\n",
    "    logreturns = np.array(data[['Daily_log_return']].dropna())\n",
    "    target = np.array(data_cleaned[['Target22']].dropna())\n",
    "\n",
    "    garch_pred = []\n",
    "    for i in range(len(data)):\n",
    "        train = logreturns[:i+22]*100\n",
    "        gm = arch_model(train, p=1, q=1)\n",
    "        gm_fit = gm.fit(disp='off')\n",
    "        pred = gm_fit.forecast(horizon=1)\n",
    "        garch_pred.append(np.sqrt(pred.variance.values[-1,:][0])*0.01*np.sqrt(252))\n",
    "\n",
    "    print('garch pred length: ', len(garch_pred))\n",
    "    print('target length: ', len(target))\n",
    "    # plot(garch_pred, target)\n",
    "    garch_pred = pd.DataFrame(garch_pred, columns=['GARCH'])\n",
    "    print('-----GARCH estimation done-----')\n",
    "    return garch_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def data_prep(data, split_index):\n",
    "    data = data.drop(['Daily_return', 'Past_vol22', 'Target10','Date'], axis=1)\n",
    "    window = 22\n",
    "    y_values = data[['Target22']]\n",
    "    x_values = data.drop(['Target22'], axis=1)\n",
    "    print(x_values.info())\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_x = scaler.fit_transform(x_values)\n",
    "    scaled_y = scaler.fit_transform(y_values)\n",
    "\n",
    "    trainX = np.array(scaled_x[:split_index])\n",
    "    testX = np.array(scaled_x[split_index:])\n",
    "    trainY = np.array(scaled_y[:split_index])\n",
    "    testY = np.array(scaled_y[split_index:])\n",
    "\n",
    "    Xtrain =[]\n",
    "    ytrain =[]\n",
    "    Xtest =[]\n",
    "    ytest = []\n",
    "\n",
    "    for i in range(window, len(trainX)):\n",
    "        Xtrain.append(trainX[i - window:i, :trainX.shape[1]])\n",
    "        ytrain.append(trainY[i])\n",
    "    for i in range(window, len(testX)):\n",
    "        Xtest.append(testX[i - window:i, :testX.shape[1]])\n",
    "        ytest.append(testY[i])\n",
    "\n",
    "    Xtrain, ytrain = (np.array(Xtrain), np.array(ytrain))\n",
    "    Xtrain = np.reshape(Xtrain, (Xtrain.shape[0], Xtrain.shape[1], Xtrain.shape[2]))\n",
    "\n",
    "    Xtest, ytest = (np.array(Xtest), np.array(ytest))\n",
    "    Xtest = np.reshape(Xtest, (Xtest.shape[0], Xtest.shape[1], Xtest.shape[2]))\n",
    "\n",
    "    print(Xtrain.shape)\n",
    "    print(ytrain.shape)\n",
    "    print(\"-----\")\n",
    "    print(Xtest.shape)\n",
    "    print(ytest.shape)\n",
    "    return Xtrain, ytrain, Xtest, ytest, scaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def create_lstm(Xtrain, n_units=2, dropout=0):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=n_units, return_sequences=False, input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "    # model.add(LSTM(units=n_units, return_sequences=True, input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "    model.add(Dropout(dropout))\n",
    "    # model.add(Dense(20, activation='tanh'))\n",
    "    # model.add(Dense(5, activation='tanh'))\n",
    "    model.add(Dense(1))\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def create_ann(Xtrain):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "    model.add(Dense(64, activation='tanh'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(20, activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    adam = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def run_lstm(Xtrain, ytrain, Xtest, ytest, scaler):\n",
    "    lstm = create_lstm(Xtrain)\n",
    "    lstm_fit = lstm.fit(Xtrain, ytrain, batch_size=16, epochs=150)\n",
    "    lstm_forecast = lstm.predict(Xtest)\n",
    "\n",
    "    rev_forecast = scaler.inverse_transform(lstm_forecast)\n",
    "    rev_ytest = scaler.inverse_transform(ytest)\n",
    "\n",
    "    plot(rev_forecast, rev_ytest)\n",
    "    evaluate(rev_forecast, rev_ytest, 'LSTM Evaluation')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def run_ann(Xtrain, ytrain, Xtest, ytest, scaler):\n",
    "    model = create_ann(Xtrain)\n",
    "    model_fit = model.fit(Xtrain, ytrain, batch_size=16, epochs=50)\n",
    "    forecast = model.predict(Xtest)\n",
    "\n",
    "    rev_forecast = scaler.inverse_transform(forecast)\n",
    "    rev_ytest = scaler.inverse_transform(ytest)\n",
    "\n",
    "    plt.plot(rev_forecast, color='red', label='forecast')\n",
    "    plt.plot(rev_ytest, color='gold', label='target')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    evaluate(rev_forecast, rev_ytest, 'GER-FNN evaluation')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "data = read_data()\n",
    "data_cleaned = data[22:].dropna().reset_index(drop=True)\n",
    "split_index = int(len(data_cleaned)*0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----EWMA estimation done-----\n",
      "garch pred length:  2321\n",
      "target length:  2299\n",
      "-----GARCH estimation done-----\n",
      "garch pred length:  2321\n",
      "target length:  2299\n",
      "-----GJR-GARCH estimation done-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/changhyun/workspace/cxk858/env/lib/python3.8/site-packages/scipy/optimize/optimize.py:282: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  warnings.warn(\"Values in x were outside bounds during a \"\n",
      "/home/changhyun/workspace/cxk858/env/lib/python3.8/site-packages/scipy/optimize/optimize.py:282: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  warnings.warn(\"Values in x were outside bounds during a \"\n",
      "/home/changhyun/workspace/cxk858/env/lib/python3.8/site-packages/scipy/optimize/optimize.py:282: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  warnings.warn(\"Values in x were outside bounds during a \"\n"
     ]
    }
   ],
   "source": [
    "ewma_estim = ewma_estimation(data_cleaned)\n",
    "garch_estim = create_garch(data)\n",
    "gjr_estim = create_gjr(data)\n",
    "# data_cleaned['EWMA'] = ewma_estim['EWMA']\n",
    "# data_cleaned['GARCH'] = garch_estim['GARCH']\n",
    "# data_cleaned['GJR'] = gjr_estim['GJR']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "data_e = data_cleaned.copy()\n",
    "data_e['EWMA'] = ewma_estim['EWMA']\n",
    "data_g = data_cleaned.copy()\n",
    "data_g['GARCH'] = garch_estim['GARCH']\n",
    "data_r = data_cleaned.copy()\n",
    "data_r['GJR'] = gjr_estim['GJR']\n",
    "data_eg = data_cleaned.copy()\n",
    "data_eg['EWMA'] = ewma_estim['EWMA']\n",
    "data_eg['GARCH'] = garch_estim['GARCH']\n",
    "data_er = data_cleaned.copy()\n",
    "data_er['EWMA'] = ewma_estim['EWMA']\n",
    "data_er['GJR'] = gjr_estim['GJR']\n",
    "data_gr = data_cleaned.copy()\n",
    "data_gr['GJR'] = gjr_estim['GJR']\n",
    "data_gr['GARCH'] = garch_estim['GARCH']\n",
    "data_egr = data_cleaned.copy()\n",
    "data_egr['EWMA'] = ewma_estim['EWMA']\n",
    "data_egr['GARCH'] = garch_estim['GARCH']\n",
    "data_egr['GJR'] = gjr_estim['GJR']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2321 entries, 0 to 2320\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Daily_trading_range  2321 non-null   float64\n",
      " 1   Log_Volume_change    2321 non-null   float64\n",
      " 2   Daily_log_return     2321 non-null   float64\n",
      " 3   Index                2321 non-null   float64\n",
      " 4   gold                 2321 non-null   float64\n",
      " 5   oil                  2321 non-null   float64\n",
      " 6   EWMA                 2321 non-null   float64\n",
      " 7   GARCH                2321 non-null   float64\n",
      " 8   GJR                  2321 non-null   float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 163.3 KB\n",
      "None\n",
      "(1834, 22, 9)\n",
      "(1834, 1)\n",
      "-----\n",
      "(443, 22, 9)\n",
      "(443, 1)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, ytrain, Xtest, ytest, scaler = data_prep(data_egr, split_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "regressor = KerasRegressor(build_fn=create_lstm, epochs=10, verbose=0, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "params = dict(n_units=[10,20,32,64],\n",
    "              epochs=[50,100],\n",
    "              batch_size=[8,16,32],\n",
    "              dropout=[0.1,0.2,0.3,0.4,0.5]\n",
    "              )\n",
    "grid = GridSearchCV(estimator=regressor, param_grid=params, verbose=10,cv=tscv)\n",
    "grid_result = grid.fit(Xtrain,ytrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}